HT1=hist(df$hour, main = "hour")
HT3=hist(df$hour_bef_precipitation, main = "hour_bef_windspeed")
par(mfrow = c(3, 4))
HT1=hist(df$hour, main = "hour")
HT2=hist(df$hour_bef_temperature, main = "hour_bef_temperature")
HT3=hist(df$hour_bef_precipitation, main = "hour_bef_precipitation")
HT4=hist(df$hour_bef_humidity, main = "hour_bef_humidity")
HT5=hist(df$hour_bef_windspeed, main = "hour_bef_windspeed")
HT6=hist(df$hour_bef_visibility, main = "hour_bef_visibility")
HT7=hist(df$hour_bef_ozone, main = "hour_bef_ozone")
HT8=hist(df$hour_bef_pm10, main = "hour_bef_pm10")
par(mfrow = c(4, 3))
HT1=hist(df$hour, main = "hour")
HT2=hist(df$hour_bef_temperature, main = "hour_bef_temperature")
HT3=hist(df$hour_bef_precipitation, main = "hour_bef_precipitation")
HT4=hist(df$hour_bef_humidity, main = "hour_bef_humidity")
par(mfrow = c(3, 3))
HT1=hist(df[,1], main = "hour")
HT2=hist(df[,2], main = "hour_bef_temperature")
par(mfrow = c(4, 3))
HT1=hist(df$hour, main = "hour")
colnames(df)
par(mfrow = c(3, 4))
HT1=hist(df[,1], main = "hour")
par(mfrow = c(4, 3))
HT1=hist(df[,1], main = "hour")
par(mfrow = c(4, 3))
HT1=hist(df[,1], main = "hour")
HT2=hist(df[,2], main = "hour_bef_temperature")
par(mfrow = c(4, 3))
HT1=hist(df[,1], main = "hour")
par(mfrow = c(4, 3))
HT1=hist(df[,1], main = "hour")
HT2=hist(df[,2], main = "hour_bef_temperature")
HT3=hist(df[,3], main = "hour_bef_precipitation")
HT4=hist(df[,4], main = "hour_bef_windspeed")
HT5=hist(df[,5], main = "hour_bef_humidity")
HT6=hist(df[,6], main = "hour_bef_visibility")
HT7=hist(df[,7], main = "hour_bef_ozone")
HT8=hist(df[,8], main = "hour_bef_pm10")
HT9=hist(df[,9], main = "hour_bef_pm2.5")
HT10=hist(df[,10], main = "count")
par(mfrow = c(3, 4))
HT1=hist(df[,1], main = "hour")
HT2=hist(df[,2], main = "hour_bef_temperature")
HT3=hist(df[,3], main = "hour_bef_precipitation")
HT4=hist(df[,4], main = "hour_bef_windspeed")
HT5=hist(df[,5], main = "hour_bef_humidity")
HT6=hist(df[,6], main = "hour_bef_visibility")
HT7=hist(df[,7], main = "hour_bef_ozone")
HT8=hist(df[,8], main = "hour_bef_pm10")
HT9=hist(df[,9], main = "hour_bef_pm2.5")
HT10=hist(df[,10], main = "count")
colnames(df)
#더미
df$morning <- ifelse(df$hour>=6 & df$hour <= 10, 1, 0)
df$evening <- ifelse(df$hour>=17 & df$hour <= 21, 1, 0)
df$morning
df$evening
df$hour <- NULL
str(df)
#정규분포화
df$countLog <- log(df$count)
df$countSqrt <- sqrt(df$count)
skewness(df$count)
skewness(df$countLog)
skewness(df$countSqrt)
colnames(df)
par(mfrow = c(1, 3))
HT1=hist(df[,9], main = "count")
HT2=hist(df[,12], main = "countLog")
HT3=hist(df[,13], main = "countSqrt")
df$count <- NULL
df$countLog <- NULL
pairs.panels(df)
#모델링
## Split & Scale
colnames(df)
scale_model <- caret::preProcess(df[,-11], method = 'range')
df_scaled <- predict(scale_model, df)
head(df_scaled)
set.seed(123)
idx_train = sample(1:nrow(df_scaled), size = 800)
df_train = df_scaled[idx_train, ]
df_test = df_scaled[-idx_train, ]
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(countSqrt~., data = df_train)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
m1 = update(m1, .~.-hour_bef_visibility-hour_bef_pm2.5-hour_bef_ozone)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
# 의사결정나무
m2 = rpart(countSqrt~., data = df_train)
summary(m2)
p2 = predict(m2, df_test);cor(df_test$countSqrt, p2)
# 랜덤 포레스트트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(countSqrt~., data = df_train, ntree = nt)
summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
for(nd in 1:30) {
m = randomForest(countSqrt~., data = df_train, maxnodes=nd)
summary(m)
p = predict(m, df_train)
cat("node =", nd, "acc =",cor(df_train$countSqrt, p),"\n")
}
OPT_NT = 50
OPT_ND = 29
m3 = randomForest(countSqrt~., data = df_train, ntree = OPT_NT, maxnodes=OPT_ND)
summary(m3)
p3 = predict(m3, df_test);cor(df_test$countSqrt, p3)
# SVM
m4 = svm(countSqrt~., data = df_train)
summary(m4)
p4 = predict(m4, df_test);cor(df_test$countSqrt, p4)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(countSqrt~., data = df_train)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
# EDA
df = read.csv('2020.AI.bike-train.csv')
str(df)
table(is.na(df))
df$id <- NULL
#더미
df$morning <- ifelse(df$hour>=6 & df$hour <= 10, 1, 0)
df$evening <- ifelse(df$hour>=17 & df$hour <= 21, 1, 0)
df$morning
df$evening
df$hour <- NULL
str(df)
#모델링
## Split & Scale
colnames(df)
par(mfrow = c(3, 4))
HT1=hist(df[,1], main = "hour_bef_temperature")
HT2=hist(df[,2], main = "hour_bef_precipitation")
par(mfrow = c(3, 4))
HT1=hist(df[,1], main = "hour_bef_temperature")
HT2=hist(df[,2], main = "hour_bef_precipitation")
HT3=hist(df[,3], main = "hour_bef_windspeed")
HT4=hist(df[,4], main = "hour_bef_humidity")
HT5=hist(df[,5], main = "hour_bef_visibility")
HT6=hist(df[,6], main = "hour_bef_ozone")
HT7=hist(df[,7], main = "hour_bef_pm10")
HT8=hist(df[,8], main = "hour_bef_pm2.5")
HT9=hist(df[,9], main = "count")
HT10=hist(df[,10], main = "morning")
HT11=hist(df[,11], main = "evening")
# EDA
df = read.csv('2020.AI.bike-train.csv')
str(df)
table(is.na(df))
df$id <- NULL
#더미
hist(df[,1], main = "hour")
#더미
HT1=hist(df[,1], main = "hour")
# EDA
df = read.csv('2020.AI.bike-train.csv')
str(df)
table(is.na(df))
summary(df)
print(summary(df))
# EDA
df = read.csv('2020.AI.bike-train.csv')
str(df)
table(is.na(df))
summary(df)
df$id <- NULL
#더미
HT1=hist(df[,1], main = "hour")
df$morning <- ifelse(df$hour>=6 & df$hour <= 10, 1, 0)
df$evening <- ifelse(df$hour>=17 & df$hour <= 21, 1, 0)
df$morning
df$evening
df$hour <- NULL
str(df)
par(mfrow = c(3, 4))
HT1=hist(df[,1], main = "hour_bef_temperature")
HT2=hist(df[,2], main = "hour_bef_precipitation")
HT3=hist(df[,3], main = "hour_bef_windspeed")
HT4=hist(df[,4], main = "hour_bef_humidity")
HT5=hist(df[,5], main = "hour_bef_visibility")
HT6=hist(df[,6], main = "hour_bef_ozone")
HT7=hist(df[,7], main = "hour_bef_pm10")
HT8=hist(df[,8], main = "hour_bef_pm2.5")
HT9=hist(df[,9], main = "count")
HT10=hist(df[,10], main = "morning")
HT11=hist(df[,11], main = "evening")
#정규분포화
df$countLog <- log(df$count)
df$countSqrt <- sqrt(df$count)
skewness(df$count)
skewness(df$countLog)
skewness(df$countSqrt)
colnames(df)
par(mfrow = c(1, 3))
HT1=hist(df[,9], main = "count")
HT2=hist(df[,12], main = "countLog")
HT3=hist(df[,13], main = "countSqrt")
df$count <- NULL
df$countLog <- NULL
pairs.panels(df)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(countSqrt~., data = df_train)
summary(m1)
m1 = update(m1, .~.-hour_bef_visibility-hour_bef_pm2.5-hour_bef_ozone)
summary(m1)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(countSqrt~., data = df_train)
summary(m1)
m1 = update(m1, .~.-hour_bef_visibility-hour_bef_pm2.5-hour_bef_ozone)
summary(m1)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(countSqrt~., data = df_train)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
#모델링
## Split & Scale
colnames(df)
formular = countSqrt~hour_bef_temperature+factor(hour_bef_precipitation)+hour_bef_windspeed+hour_bef_humidity+hour_bef_visibility+hour_bef_ozone+hour_bef_pm10+hour_bef_pm2.5+factor(morning)+factro(evening)
m1 = lm(formular, data = df_train)
formular = countSqrt~hour_bef_temperature+factor(hour_bef_precipitation)+hour_bef_windspeed+hour_bef_humidity+hour_bef_visibility+hour_bef_ozone+hour_bef_pm10+hour_bef_pm2.5+factor(morning)+factor(evening)
m1 = lm(formular, data = df_train)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(formular, data = df_train)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
head(df_scaled)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(formular, data = df_train)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
m1 = update(m1, .~.-hour_bef_visibility-hour_bef_pm2.5-hour_bef_ozone)
summary(m1)
p1 = predict(m1, df_test);cor(df_test$countSqrt, p1)
# 의사결정나무
m2 = rpart(formular, data = df_train)
summary(m2)
summary(m2)
# 의사결정나무
m2 = rpart(formular, data = df_train)
summary(m2)
p2 = predict(m2, df_test);cor(df_test$countSqrt, p2)
par(mfrow=c(1,1), xpd=NA)
plot(m2)
text(m2, use.n = TRUE)
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(formular, data = df_train, ntree = nt)
summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
# 의사결정나무
m2 = rpart(formular, data = df_train)
m3 = randomForest(formular, data = df_train, ntree = OPT_NT, maxnodes=OPT_ND)
# EDA
df = read.csv('2020.AI.bike-train.csv')
str(df)
table(is.na(df))
summary(df)
df$id <- NULL
HT1=hist(df[,1], main = "hour")
df$morning <- ifelse(df$hour>=6 & df$hour <= 10, 1, 0)
df$evening <- ifelse(df$hour>=17 & df$hour <= 21, 1, 0)
df$morning
df$evening
df$hour <- NULL
str(df)
df$countLog <- log(df$count)
df$countSqrt <- sqrt(df$count)
skewness(df$count)
skewness(df$countLog)
skewness(df$countSqrt)
colnames(df)
par(mfrow = c(1, 3))
HT1=hist(df[,9], main = "count")
HT2=hist(df[,12], main = "countLog")
HT3=hist(df[,13], main = "countSqrt")
df$count <- NULL
df$countLog <- NULL
scale_model <- caret::preProcess(df[,-11], method = 'range')
df_scaled <- predict(scale_model, df)
head(df_scaled)
set.seed(123)
idx_train = sample(1:nrow(df_scaled), size = 800)
df_train = df_scaled[idx_train, ]
df_test = df_scaled[-idx_train, ]
formular = countSqrt~hour_bef_temperature+factor(hour_bef_precipitation)+hour_bef_windspeed+hour_bef_humidity+hour_bef_visibility+hour_bef_ozone+hour_bef_pm10+hour_bef_pm2.5+factor(morning)+factor(evening)
#https://bioinformaticsandme.tistory.com/290
# 다중회귀분석
m1 = lm(formular, data = df_train)
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(formular, data = df_train, ntree = nt)
summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(formular, data = df_train, ntree = nt)
summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(formular, data = df_train, ntree = nt)
summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")}
for(nd in 1:30) {
m = randomForest(formular, data = df_train, maxnodes=nd)
summary(m)
p = predict(m, df_train)
cat("node =", nd, "acc =",cor(df_train$countSqrt, p),"\n")
}
m3 = randomForest(formular, data = df_train, ntree = OPT_NT, maxnodes=OPT_ND)
# SVM
m4 = svm(formular, data = df_train)
summary(m4)
p4 = predict(m4, df_test);cor(df_test$countSqrt, p4)
library(moments)
#install.packages('psych')
library(psych)
library(caret)
library(doBy)
library(randomForest)
library(e1071)
library(rpart)
m3 = randomForest(formular, data = df_train, ntree = OPT_NT, maxnodes=OPT_ND)
m3 = randomForest(countSqrt~., data = df_train, ntree = OPT_NT, maxnodes=OPT_ND)
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(countSqrt~., data = df_train, ntree = nt)
summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")}
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(countSqrt~., data = df_train, ntree = nt)
#summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)) {
m = randomForest(countSqrt~., data = df_train, ntree = nt)
#summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500))
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)){
m = randomForest(countSqrt~., data = df_train, ntree = nt)
#summary(m)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
df$
# 랜덤 포레스트
for(nt in c(20,50,100,200,300,400,500)){
m = randomForest(countSqrt~., data = df_train, ntree = nt)
p = predict(m, df_train)
cat("ntree =",nt,"acc =",cor(df_train$countSqrt, p),"\n")
}
for(nd in 1:30) {
m = randomForest(countSqrt~., data = df_train, maxnodes=nd)
#summary(m)
p = predict(m, df_train)
cat("node =", nd, "acc =",cor(df_train$countSqrt, p),"\n")
}
m3 = randomForest(countSqrt~., data = df_train)
p3 = predict(m3, df_test);cor(df_test$countSqrt, p3)
m3 = randomForest(countSqrt~., data = df_train, ntree = OPT_NT, maxnodes=OPT_ND)
p3 = predict(m3, df_test);cor(df_test$countSqrt, p3)
df$
# 랜덤 포레스트
m3 = randomForest(countSqrt~., data = df_train)
summary(m3)
p3 = predict(m3, df_test);cor(df_test$countSqrt, p3)
df$
# 랜덤 포레스트
m3 = randomForest(countSqrt~., data = df_train)
df$
# 랜덤 포레스트
m3 = randomForest(countSqrt~., data = df_train)
df$
# 랜덤 포레스트
m13 = randomForest(countSqrt~., data = df_train)
summary(m4)
varUsed(m3)
varImpPlot(m3)
getwd()
setwd('C:/Users/82104/my-workspace/R-workspace/')
rm(list = ls())
#install.packages("moments")
library(moments)
#install.packages('psych')
library(psych)
library(caret)
library(doBy)
library(randomForest)
library(e1071)
library(rpart)
df = read.csv('2020.AI.bike-train.csv')
str(df)
table(is.na(df))
summary(df)
df$id <- NULL
df$morning <- ifelse(df$hour>=6 & df$hour <= 10, 1, 0)
df$evening <- ifelse(df$hour>=17 & df$hour <= 21, 1, 0)
df$morning
df$evening
df$hour <- NULL
str(df)
df$countLog <- log(df$count)
df$countSqrt <- sqrt(df$count)
skewness(df$count)
skewness(df$countLog)
skewness(df$countSqrt)
colnames(df)
df$count <- NULL
df$countLog <- NULL
scale_model <- caret::preProcess(df[,-11], method = 'range')
df_scaled <- predict(scale_model, df)
head(df_scaled)
set.seed(123)
idx_train = sample(1:nrow(df_scaled), size = 800)
df_train = df_scaled[idx_train, ]
df_test = df_scaled[-idx_train, ]
formular = countSqrt~hour_bef_temperature+factor(hour_bef_precipitation)+hour_bef_windspeed+hour_bef_humidity+hour_bef_visibility+hour_bef_ozone+hour_bef_pm10+hour_bef_pm2.5+factor(morning)+factor(evening)
df$
# 랜덤 포레스트
m13 = randomForest(countSqrt~., data = df_train)
df$
# 랜덤 포레스트
m13 = randomForest(formular, data = df_train)
summary(m3)
summary(m13)
# 의사결정나무
m2 = rpart(formular, data = df_train)
summary(m2)
p2 = predict(m2, df_test);cor(df_test$countSqrt, p2)
df$
# 랜덤 포레스트
m3 = randomForest(formular -hour_bef_precipitation, data = df_train)
formular2 = countSqrt~hour_bef_temperature+hour_bef_windspeed+hour_bef_humidity+hour_bef_visibility+hour_bef_ozone+hour_bef_pm10+hour_bef_pm2.5+factor(morning)+factor(evening)
df$
# 랜덤 포레스트
m3 = randomForest(formular2, data = df_train)
formular_noFactor = countSqrt~hour_bef_temperature+hour_bef_windspeed+hour_bef_humidity+hour_bef_visibility+hour_bef_ozone+hour_bef_pm10+hour_bef_pm2.5
df$
# 랜덤 포레스트
m3 = randomForest(formular_noFactor, data = df_train)
summary(m3)
df$
# 랜덤 포레스트
colnames(df_scaled)
m3 = randomForest(formular_noFactor, data = df_train)
summary(m3)
p3 = predict(m3, df_test);cor(df_test$countSqrt, p3)
m3 = randomForest(formular, data = df_train)
m3 = randomForest(formular_noFactor, data = df_train)
summary(m3)
p3 = predict(m3, df_test);cor(df_test$countSqrt, p3)
varUsed(m3)
varImpPlot(m3)
# SVM
m4 = svm(formular, data = df_train)
summary(m4)
p4 = predict(m4, df_test);cor(df_test$countSqrt, p4)
#cv
control = trainControl(method = 'cv', number=10)
s = train(formular, data=df_train, method='svmLinear', metric='RMSE',trControl=control)
rf = train(formular, data=df_train, method='rf', metric='RMSE',trControl=control)
sp = train(formular, data=df_train, method='svmPoly', metric='RMSE',trControl=control)
sr = train(formular, data=df_train, method='svmRadial', metric='RMSE',trControl=control)
r = train(formular, data=df_train, method='rpart', metric='RMSE',trControl=control)
lm = train(formular, data=df_train, method='lm', metric='RMSE',trControl=control)
k = train(formular, data=df_train, method='knn', metric='RMSE',trControl=control)
resamp = resamples(list(svm=s, svmPoly=sp, svmRadial=sr, RF=rf, decisionTree=r, regression=lm,kNN=k))
summary(resamp)
sort(resamp,decreasing = TRUE)
dotplot(resamp)
