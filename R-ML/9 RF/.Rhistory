rm(list = ls())
getwd()
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
getwd()
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
table(D.table)
table(D.date)
table(D.data)
prop.table(table(D.data$Class))
Tra <- read.csv("Tra1.csv",header = T)
Tra <- read.csv("Tra1.csv",header = T)
Val <- read.csv("Val1.csv",header = T)
Tes <- read.csv("Tes1.csv",header = T)
prop.table(table(Tra$Class))
prop.table(table(Val$Class))
prop.table(table(Tes$Class))
table(Tra$Class)
table(Val$Class)
table(Tes$Class)
View(Tra)
D.tra <- Tra[,-c(1)]
D.val <- Val[,-c(1)]
View(Tra)
View(D.tra)
# Building Decision Tree
install.packages("rpart")
library(rpart)
#rpart는 반드시 seed지정 후 사용
tseed <-12345
set.seed(tseed)
#rpart는 반드시 seed지정 후 사용
tseed <-12345
set.seed(tseed)
# Entropy
e_DT <- rpart(class~.,D.tra,method = 'class',parms = list(split='information'))
# Entropy
e_DT <- rpart(Class~.,D.tra,method = 'class',parms = list(split='information'))
plot(e_DT)
text(e_DT)
# Entropy
e_DT <- rpart(Class~.,D.tra,method = 'class',parms = list(split='information'))
plot(e_DT)
text(e_DT)
plot(e_DT,margin = 0.2)
text(e_DT)
table(D.tra$Thal)
e_Dt
e_DT
Predict.tra <- predict(e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
head(Predict.tra)
head(Actual.tra)
#Confusion Matrix (예측,실제)
library(caret)
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
library(e1071)
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
Predict.tra <- predict(e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
head(Predict.tra)
head(Actual.tra)
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
head(Predict.tra)
head(Actual.tra)
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
#acc0.8708,sen 0.0924 spec 0.8438
cTab <- table(Actual.tra,Predict.tra)
cTab
CM.tra <- confusionMatrix(t(cTab),positive = 'Disease')
CM.tra
CM.tra$overall['Accuracy']
CM.tra$byClass['Sensitivity']
CM.tra$byClass['Specificity']
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
Accu.tra*100
Predict.tra <- predict(e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
cTab <- table(Actual.tra,Predict.tra)
CM.tra <- confusionMatrix(t(cTab),positive = 'Disease')
Accu.tra <- CM.tra$overall['Accuracy']
cTab
Accu.tra*100
# Pruning
printcp(e_Dt)
# Pruning
printcp(e_DT)
cpVal <- e_DT$cptable[which.min(e_DT$cptable[,'xerror']),'CP']
cpVal
cpVal <- e_DT$cptable[which.min(e_DT$cptable[,'xerror']),'cp']
cpVal
cpVal <- e_DT$cptable[which.min(e_DT$cptable[,'xerror']),'CP']
cpVal
pruned.e_DT <- prune(e_DT,cp=cpVal)
plot(pruned.e_DT,margin = 0.2)
text(pruned.e_DT)
Predict.tra <- predict(pruned.e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
cTab <- table(Actual.tra,Predict.tra)
CM.tra <- confusionMatrix(t(cTab),positive = 'Disease')
Accu.tra <- CM.tra$overall['Accuracy']
cTab
Accu.tra*100
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
Predict.tra <- predict(e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
head(Predict.tra)
head(Actual.tra)
head(Tra)
head(Val)
D.data$Class[1:5]
Predict.tra$Class[1:5]
Predict.tra <- predict(e_DT,D.tra,type="class")
Predict.tra$Class[1:5]
Predict.tra[1:5]
e_DT <- rpart(Class~., D.tra, method='class',parms=list(split="gini"))
g_DT <- rpart(Class~., D.tra, method='class',parms=list(split="gini"))
rm(list = ls())
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
data<-read.csv("pjhData.csv",header = T)
getwd()
data<-read.csv("pjhData.csv",header = T)
rm(list = ls())
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
Training
Validation
Test
rm(list = ls())
getwd()
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
Tra <- read.csv("Tra1.csv",header = T)
Val <- read.csv("Val1.csv",header = T)
Tes <- read.csv("Tes1.csv",header = T)
table(D.data)
table(Tra$Class)
table(Val$Class)
table(Tes$Class)
head(Tra)
head(Val)
D.data$Class[1:5]
prop.table(table(D.data$Class))
prop.table(table(Tra$Class))
prop.table(table(Val$Class))
prop.table(table(Tes$Class))
D.tra <- Tra[,-c(1)]
D.val <- Val[,-c(1)]
# Building Decision Tree
library(rpart)
#rpart는 반드시 seed지정 후 사용
tseed <-12345
set.seed(tseed)
# Entropy
e_DT <- rpart(Class~.,D.tra,method = 'class',parms = list(split='information'))
plot(e_DT,margin = 0.2)
text(e_DT)
# Entropy
e_DT <- rpart(Class~.,D.tra,method = 'class',parms = list(split='information'))
plot(e_DT,margin = 0.2)
text(e_DT)
plot(e_DT,margin = 0.2)
text(e_DT)
table(D.tra$Thal) #t6,7 왼쪽 으로간다  bc
e_DT
version
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
Training
Validation
Test
rm(list = ls())
rm(list = ls())
getwd()
#UCI machine learning repository
D.data <- read.csv("HeartD.csv",header = T)
Tra <- read.csv("Tra1.csv",header = T)
Val <- read.csv("Val1.csv",header = T)
Tes <- read.csv("Tes1.csv",header = T)
table(D.data)
table(Tra$Class)
table(Val$Class)
table(Tes$Class)
head(Tra)
head(Val)
D.data$Class[1:5]
prop.table(table(D.data$Class))
prop.table(table(Tra$Class))
prop.table(table(Val$Class))
prop.table(table(Tes$Class))
D.tra <- Tra[,-c(1)]
D.val <- Val[,-c(1)]
# Building Decision Tree
library(rpart)
#rpart는 반드시 seed지정 후 사용
tseed <-12345
set.seed(tseed)
# Entropy
e_DT <- rpart(Class~.,D.tra,method = 'class',parms = list(split='information'))
plot(e_DT,margin = 0.2)
text(e_DT)
table(D.tra$Thal) #t6,7 왼쪽 으로간다  bc
e_DT
version
Predict.tra <- predict(e_DT,D.tra,type="class")
Predict.tra[1:5]
Actual.tra <- D.tra$Class
head(Predict.tra)
head(Actual.tra)
#Confusion Matrix (예측,실제)
library(caret)
library(e1071)
CM1 <- confusionMatrix(Predict.tra,Actual.tra,positive = 'Disease')
#acc0.8708,sen 0.0924 spec 0.8438
cTab <- table(Actual.tra,Predict.tra)
cTab#이게우리가원하는거
CM.tra <- confusionMatrix(t(cTab),positive = 'Disease')
CM.tra
CM.tra$overall['Accuracy']
CM.tra$byClass['Sensitivity']
CM.tra$byClass['Specificity']
#Suming Up
Predict.tra <- predict(e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
cTab <- table(Actual.tra,Predict.tra)
CM.tra <- confusionMatrix(t(cTab),positive = 'Disease')
Accu.tra <- CM.tra$overall['Accuracy']
cTab
Accu.tra*100
#val로바꾸기
Predict.val <- predict(e_DT,D.val,type="class")
Actual.val <- D.val$Class
cTab <- table(Actual.val,Predict.val)
CM.val <- confusionMatrix(t(cTab),positive = 'Disease')
Accu.val <- CM.val$overall['Accuracy']
cTab
Accu.val*100
# Pruning
printcp(e_DT)#xerror 제일작은거찾기: 3
cpVal <- e_DT$cptable[which.min(e_DT$cptable[,'xerror']),'CP']
cpVal
pruned.e_DT <- prune(e_DT,cp=cpVal)
plot(pruned.e_DT,margin = 0.2)
text(pruned.e_DT)
Predict.tra <- predict(pruned.e_DT,D.tra,type="class")
Actual.tra <- D.tra$Class
cTab <- table(Actual.tra,Predict.tra)
CM.tra <- confusionMatrix(t(cTab),positive = 'Disease')
Accu.tra <- CM.tra$overall['Accuracy']
cTab
Accu.tra*100
#val로바꾸기
Predict.val <- predict(pruned.e_DT,D.val,type="class")
Actual.val <- D.val$Class
cTab <- table(Actual.val,Predict.val)
CM.val <- confusionMatrix(t(cTab),positive = 'Disease')
Accu.val <- CM.val$overall['Accuracy']
cTab
Accu.val*100
#Gini
g_DT<- rpart(cl)
g_DT <- rpart(Class~., D.tra, method='class',parms=list(split="gini"))
setwd('C:/R DA-ML/9 RF')
Tra <- read.csv("Tra1.csv",header = T)
Val <- read.csv("Val1.csv",header = T)
Tes <- read.csv("Tes1.csv",header = T)
D.tra <- Tra[,-c(1)]
D.val <- Val[,-c(1)]
D.tes <- Tes[,-c(1)]
cpVal <- e_DT$cptable[which.min(e_DT$cptable[,'xerror']),'CP']
cpVal
pruned.e_DT <- prune(e_DT,cp=cpVal)
plot(pruned.e_DT,margin = 0.2)
install.packages('ramdomForest')
library(randomForest)
install.packages('ramdomForest')
library(randomForest)
x <- subset(D.tra,select=-c(Class))
y <- D.tra$Class
version
#Confusion Matrix (예측,실제)
library(caret)
library(e1071)
install.packages('ramdomForest')
install.packages('ramdomForest')
set.seed(mtrySeed)
mtrySeed <- 1234
set.seed(mtrySeed)
bestmtry <- tuneRF(x,y,stepFactor=1.5,improve=0.001,ntreeTry=49)
install.packages('ramdomForest')
nTree <- 49
mTry <- 4
rfSeed <- 123
set.seed(rfSeed)
library(randomForest)
x <- subset(D.tra,select=-c(Class))
y <- D.tra$Class
mtrySeed <- 1234
set.seed(mtrySeed)
bestmtry <- tuneRF(x,y,stepFactor=1.5,improve=0.001,ntreeTry=49)
rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry)
Predict.tra <- predict(rfModel,D.tra)
cTab <- table(Acutal=D.tra$Class,predict.tra)
library(randomForest)
x <- subset(D.tra,select=-c(Class))
y <- D.tra$Class
mtrySeed <- 1234
set.seed(mtrySeed)
bestmtry <- tuneRF(x,y,stepFactor=1.5,improve=0.001,ntreeTry=49)
levels(D.val$CP)<-levels(D.tra$CP)
levels(D.val$Restecg)<-levels(D.tra$Restecg)
levels(D.val$Slope)<-levels(D.tra$Slope)
levels(D.val$Thal)<-levels(D.tra$Thal)
#val바꾸기
Predict.val <- predict(rfModel,D.val)
cTab <- table(Acutal=D.val$Class,predict.val)
cTab
Accu.val <= sum(diag(cTab))/sum(cTab)*100
Accu.val
rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry)
# Pruning
maxLeaf <- 16
pruned.rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry,maxcodes=maxLeaf)
Predict.tra <- predict(pruned.rfModel,D.tra)
pruned.rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry,maxcodes=maxLeaf)
set.seed(rfSeed)
pruned.rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry,maxcodes=maxLeaf)
Variance<- abs(Accu.tra-Accu.val)
nTree; mTry; maxLeaf
str(D.tra)
#install.packages('ramdomForest')
library(randomForest)
x <- subset(D.tra,select=-c(Class))
y <- D.tra$Class
mtrySeed <- 1234
set.seed(mtrySeed)
str(D.tra)
mtrySeed <- 1234
set.seed(mtrySeed)
bestmtry <- tuneRF(x,y,stepFactor=1.5,improve=0.001,ntreeTry=49)
y <- factor(D.tra$Class)
mtrySeed <- 1234
set.seed(mtrySeed)
bestmtry <- tuneRF(x,y,stepFactor=1.5,improve=0.001,ntreeTry=49)
nTree <- 49
mTry <- 4
rfSeed <- 123
set.seed(rfSeed)
rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry)
D.tra$Class <- factor(D.tra$Class)
rfModel<- randomForest(Class~.,D.tra,ntree=nTree,mtry=mTry)
Predict.tra <- predict(rfModel,D.tra)
cTab <- table(Acutal=D.tra$Class,predict.tra)
Predict.tra <- predict(rfModel,D.tra)
cTab <- table(Acutal=D.tra$Class,Predict.tra)
cTab
Accu.tra <= sum(diag(cTab))/sum(cTab)*100
Accu.tra
rm(list = ls())
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
data<-read.csv("pjhData.csv",header = T)
rm(list = ls())
library(doBy)
rm(list = ls())
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
Training
Validation
Test
data<-read.csv("pjhData.csv",header = T)
rm(list = ls())
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
Training
Validation
Test
