### 로지스틱회귀분석
str(finalData)
summary(finalData)
pSeed<-12345
set.seed(pSeed)
training800 <-stratified(finalData,"이탈여부",0.8)
testing200 <-finalData[!finalData$고객ID%in%training800$고객ID,]
table(training800$이탈여부)
table(testing200$이탈여부)
training800<-training800[,-1]
model1_1 <- glm(이탈여부~.,data = training800,family = binomial(link = "logit"))
summary(model1_1)
model1_2 <- stepAIC(model1_1,direction = "both")
(vif_vars <- as.data.frame(vif(model1_2)))
model1_3 <- glm(이탈여부~성별+d.dummy.고+d.dummy.중저+연령+서비스기간+단선횟수+주간통화횟수+주간통화시간_분+야간통화횟수+주말통화횟수+주말통화시간_분+국내통화시간_분,data = training800,family = binomial)
pred <- predict(model1_2,newdata = testing200[,which(colnames(testing200)!= "이탈여부")],type = "response")
# check model test
pred_churn <- factor(ifelse(pred >= 0.50, "Yes", "No"))
actual_churn <- factor(ifelse(testing200$이탈여부==1,"Yes","No"))
pred_churn
############ Bayes
bayDf <- finalData[,c(1,4,10:20)]
bay.train <- stratified(bayDf,"이탈여부",0.8)
bay.test <- bayDf[!bayDf$고객ID%in%bay.train$고객ID,]
trainingLabels <- bay.train$이탈여부
testingLabels <- bay.test$이탈여부
model2 <- naiveBayes(bay.train,trainingLabels)
pred2<-predict(model2,bay.test[,which(colnames(bay.test)!= "이탈여부")])
pred2
pred2
table(pred2)
CrossTable(pred2,testingLabels,prop.chisq = FALSE, prop.t = FALSE,
prop.r = FALSE, dnn = c('predicted', 'actual'))
pred_churn2 <- factor(ifelse(pred2==1,"Yes","No"))
caret::confusionMatrix(pred_churn2,actual_churn,positive = "No")
### LDA
ldaDf <- finalData[,-c(10:20)]
lda.train <- stratified(ldaDf,"이탈여부",0.8)
lda.test <- ldaDf[!ldaDf$고객ID%in%lda.train$고객ID,]
model3 <- lda(이탈여부 ~성별+통화품질불만, data =lda.train)
model3
pred3 <- predict(model3,newdata = lda.test[,which(colnames(lda.test)!= "이탈여부")])
pred_churn3 <- factor(ifelse(pred3$class==1,"Yes","No"))
###########에측
telTest <- read.csv("ChurnDataTest.csv",stringsAsFactors = F)
telTest <-telTest[,-c(21:26)]
telTest <- telTest[1:200,]
str
d2 <- telTest[,c(2,16,19,20)]
###########에측
telTest <- read.csv("ChurnDataTest.csv",stringsAsFactors = F)
telTest <-telTest[,-c(21:26)]
telTest <- telTest[1:200,]
d2 <- telTest[,c(2,16,19,20)]
attach(d2)
d2$성별[성별=="남"] <- 1
d2$성별[성별=="여"] <- 0
d2$통화품질불만[통화품질불만==T]<-1 #논리형이라 F는 자동으로 0
detach(d2)
d2$d.dummy.고 <- ifelse(d2$통화량구분=="고",1,0)
d2$d.dummy.중고 <- ifelse(d2$통화량구분=="중고",1,0)
d2$d.dummy.중 <- ifelse(d2$통화량구분=="중",1,0)
d2$d.dummy.중저 <- ifelse(d2$통화량구분=="중저",1,0)
d2$d.dummy.저 <- ifelse(d2$통화량구분=="저",1,0)
d2<-d2[,-2]
###수치형 +표준화
d_int2 <- telTest[,c(3,4,5,17,18,7,9,11,12,14,15)]
###수치형 +표준화
d_int2 <- telTest[,c(3,4,5,17,18,7,9,11,12,14,15)]
d_int2 <- scale(d_int2)
testDf<- cbind(d2,telTest[,-c(1,2,16,19,20)])
testDf$성별<-as.numeric(testDf$성별)
str(testDf)
testDf[,1]<-factor(testDf[,1])
testDf[,2]<-factor(testDf[,2])
testDf[,4]<-factor(testDf[,4])
testDf[,5]<-factor(testDf[,5])
testDf[,6]<-factor(testDf[,6])
testDf[,7]<-factor(testDf[,7])
testDf[,8]<-factor(testDf[,8])
###로지스틱 test
test.pred <- predict(model1_2,newdata = testDf[,which(colnames(testDf)!= "이탈여부")],type = "response")
test.pred_churn <- factor(ifelse(test.pred >= 0.5, "이탈", "유지"))
table(test.pred_churn)
test.pred_churn <- factor(ifelse(test.pred >= 0.5, "이탈", "유지지"))
test.pred_churn <- factor(ifelse(test.pred >= 0.5, "이탈", "유지"))
test.pred_churn
table(test.pred_churn)
output <- cbind(telTest,test.pred_churn)
View(output)
이탈여부부 <- factor(ifelse(test.pred >= 0.5, "이탈", "유지"))
이탈여부 <- factor(ifelse(test.pred >= 0.5, "이탈", "유지"))
output <- cbind(telTest,이탈여부부)
output <- cbind(telTest,이탈여부)
output <-output[,-20]
write.csv(output,"민호준_Churn.csv")
trainingLabels <- bay.train$이탈여부
testingLabels <- bay.test$이탈여부
model2 <- naiveBayes(bay.train,trainingLabels)
pred2<-predict(model2,newdata=bay.test[,which(colnames(bay.test)!= "이탈여부")])
pred2
table(pred2)
caret::confusionMatrix(pred_churn2,actual_churn,positive = "No")
str(testDf)
testDf[,8]<-factor(testDf[,8])
View(testDf)
###로지스틱 test
test.pred <- predict(model1_2,newdata = testDf[,which(colnames(testDf)!= "이탈여부")],type = "response")
test.pred
이탈여부 <- factor(ifelse(test.pred >= 0.5, "이탈", "유지"))
test.pred_churn
test.pred_churn
telTest <- telTest[1:200,]
View(telTest)
output <- cbind(telTest,이탈여부)
output <-output[,-20]
caret::confusionMatrix(pred_churn,actual_churn,positive = "이탈탈")
library(tidyverse)
library(VIM)
library(cowplot)
library(ggcorrplot)
library(GGally)
library(ggthemes)
library(MASS)
library(car)
library(caret)
library(ROCR)
library(e1071)
library(gmodels)
library(splitstackshape)
finalData$이탈여부
load("telData20210317.Rda")
summary(finalData)
caret::confusionMatrix(pred_churn,actual_churn,positive = "이탈탈")
pSeed<-12345
set.seed(pSeed)
training800 <-stratified(finalData,"이탈여부",0.8)
testing200 <-finalData[!finalData$고객ID%in%training800$고객ID,]
table(training800$이탈여부)
table(testing200$이탈여부)
table(finalData$이탈여부)
table(training800$이탈여부)
table(testing200$이탈여부)
table(finalData$이탈여부)
table(training800$이탈여부)
table(testing200$이탈여부)
###로지스틱 test
test.pred <- predict(model2,newdata = testDf[,which(colnames(testDf)!= "이탈여부")],type = "response")
testDf[,4]<-factor(testDf[,4])
testDf[,5]<-factor(testDf[,5])
testDf[,6]<-factor(testDf[,6])
testDf[,7]<-factor(testDf[,7])
testDf[,8]<-factor(testDf[,8])
test.pred
###로지스틱 test
test.pred <- predict(model2,newdata = testDf[,which(colnames(testDf)!= "이탈여부")],type = "response")
## bayes test
bayDf2 <- testDf[,c(3,9:19)]
test.pred2<-predict(model2,bayDf2[,which(colnames(bayDf2)!= "이탈여부")])
############ Bayes
bayDf <- finalData[,c(1,4,10:20)]
bay.train <- stratified(bayDf,"이탈여부",0.8)
bay.test <- bayDf[!bayDf$고객ID%in%bay.train$고객ID,]
trainingLabels <- bay.train$이탈여부
testingLabels <- bay.test$이탈여부
model2 <- naiveBayes(bay.train,trainingLabels)
trainingLabels <- bay.train$이탈여부
testingLabels <- bay.test$이탈여부
model2 <- naiveBayes(bay.train,trainingLabels)
library(tidyverse)
library(VIM)
library(cowplot)
library(ggcorrplot)
library(GGally)
library(ggthemes)
library(MASS)
library(car)
library(caret)
library(ROCR)
library(e1071)
library(gmodels)
library(splitstackshape)
trainingLabels <- bay.train$이탈여부
testingLabels <- bay.test$이탈여부
model2 <- naiveBayes(bay.train,trainingLabels)
pred2<-predict(model2,newdata=bay.test[,which(colnames(bay.test)!= "이탈여부")])
pred2
table(pred2)
test.pred2<-predict(model2,bayDf2[,which(colnames(bayDf2)!= "이탈여부")])
## bayes test
bayDf2 <- testDf[,c(3,9:19)]
test.pred2<-predict(model2,bayDf2[,which(colnames(bayDf2)!= "이탈여부")])
test.pred2
이탈여부 <- factor(ifelse(test.pred2 = 1, "이탈", "유지"))
이탈여부 <- factor(ifelse(test.pred2 == 1, "이탈", "유지"))
###########에측
telTest <- read.csv("ChurnDataTest.csv",stringsAsFactors = F)
telTest <-telTest[,-c(21:26)]
telTest <- telTest[1:200,]
output <- cbind(telTest,이탈여부부)
output <-output[,-20]
View(output)
table(이탈여부부)
table(이탈여부)
output2 <- cbind(telTest,이탈여부)
이탈여부 <- factor(ifelse(test.pred2 == 1, "이탈", "유지"))
output2 <- cbind(telTest,이탈여부)
View(output2)
output2 <- output2[,-20]
write.csv(output2,"박지헌헌_Churn.csv")
write.csv(output2,"박지헌_Churn.csv")
table(이탈여부)
library(caret)
mds<-read.csv("sampleData.csv")
getwd()
mds<-read.csv("sampleData.csv")
mds<-read.csv("sampleData.csv",header = F)
View(mds)
mds<-read.csv("sampleData.csv",header = F)
mds<-read.csv("sampleData.csv",header = F)
View(mds)
mds<-read.csv("sampleData.csv")
View(mds)
mds<-read.csv("sampleData.csv")
View(mds)
table(mds$z)
library(caret)
mds<-read.csv("sampleData.csv")
table(mds$z)
table(mds$Z)
View(mds)
ss <- createDataPartition(mds$Z,p=trainingRate)
trainingRate <- 0.5
validationRate <- 0.3
testRate <- 0.2
ss <- createDataPartition(mds$Z,p=trainingRate)
View(ss)
split <- createDataPartition(mds$Z,p=trainingRate)
split <- createDataPartition(mds$Z,times = 2,p=trainingRate)
View(split)
split <- createDataPartition(mds$Z,times = 2,p=trainingRate,p=validationRate)
split <- createDataPartition(mds$Z,times = 2,p=trainingRate)
set.seed(1234)
split <- createDataPartition(mds$Z,times = 2,p=trainingRate)
View(split)
split <- createDataPartition(mds$Z,p=trainingRate)
trainingSet <- mds[split,]
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
trainingSet <- mds[split,]
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
trainingSet <- mds[split,]
View(trainingSet)
tempSet <- mds[-split,]
View(tempSet)
table(trainingSet$Z)
trainingRate <- 0.5
validationRate <- 0.3
testRate <- 0.2
set.seed(1234)
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
trainingSet <- mds[split,]
tempSet <- mds[-split,]
table(trainingSet$Z)
set.seed(1234)
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
trainingSet <- mds[split,]
tempSet <- mds[-split,]
table(trainingSet$Z)
table(tempSet$Z)
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
trainingSet <- mds[split,]
tempSet <- mds[-split,]
table(trainingSet$Z)
table(tempSet$Z)
1-traingset
1-traingRate
trainingRate <- 0.5
1-traingRate
1-trainingRate
trainingRate <- 0.5
validationRate <- 0.3
testRate <- 1-(trainingRate+validationRate)
table(trainingSet$Z)
table(tempSet$Z)
validationSet <- createDataPartition(tempSet$Z,p=validationRate/(1-trainingRate),list = F)
split2 <- createDataPartition(tempSet$Z,p=validationRate/(1-trainingRate),list = F)
validationSet <- tempSet[split2,]
View(validationSet)
testSet <- tempSet[-split2,]
table(validationSet$Z)
table(testSet$Z)
split2 <- createDataPartition(tempSet$Z,p=validationRate/(1-trainingRate),list = F)
validationSet <- tempSet[split2,]
testSet <- tempSet[-split2,]
table(validationSet$Z)
table(testSet$Z)
table(trainingSet$Z)
table(tempSet$Z)
trainingSet
split2 <- createDataPartition(tempSet$Z,p=validationRate/(1-trainingRate),list = F)
validationSet <- tempSet[split2,]
testSet <- tempSet[-split2,]
table(validationSet$Z)
table(testSet$Z)
split2 <- createDataPartition(tempSet$Z,p=validationRate/(1-trainingRate),list = F)
validationSet <- tempSet[split2,]
testSet <- tempSet[-split2,]
table(validationSet$Z)
table(testSet$Z)
trainingSet
validationSet
testSet
install.packages("doBy")
library(doBY)
library(doBy)
sampleBy(~Z,frac = 0.5,data = mds)
s <- sampleBy(~Z,frac = 0.5,data = mds)
View(s)
ss <- mds[s,]
View(s)
training_data <- sampleBy(formula=~Z, frac = tra_ratio, replace = FALSE , systematic=FALSE, data=mds)
training_data <- sampleBy(formula=~Z, frac = traningRate, replace = FALSE , systematic=FALSE, data=mds)
trainingRate <- 0.5
training_data <- sampleBy(formula=~Z, frac = traningRate, replace = FALSE , systematic=FALSE, data=mds)
training_data <- sampleBy(formula=~Z, frac = trainingRate, replace = FALSE , systematic=FALSE, data=mds)
View(training_data)
mds<-read.csv("sampleData.csv")
table(mds$Z)
training_data <- sampleBy(formula=~Z, frac = trainingRate, replace = FALSE , systematic=FALSE, data=mds)
View(training_data)
row.names(training_data) <- training_data$Record
View(training_data)
library(caret)
mds<-read.csv("sampleData.csv")
table(mds$Z)
trainingRate <- 0.5
validationRate <- 0.3
set.seed(1234)
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
View(split)
trainingSet <- mds[split,]
View(trainingSet)
mds<-read.csv("pjhData.csv")
table(mds$Z)
mds<-read.csv("pjhData.csv",header = T)
View(mds)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
split <- createDataPartition(mds$Z,p=trainingRate,list = F)
Training <- mds[split,]
tempSet <- mds[-split,]
split2 <- createDataPartition(tempSet$Z,p=validationRate/(1-trainingRate),list = F)
Validation <- tempSet[split2,]
Test <- tempSet[-split2,]
Training
Validation
Test
library(doby)
library(doBy)
mds<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
View(Training)
tra.row <-sort(Training$Record)
View(Training)
Training<-data[tra.row,]
View(Training)
temp <-data[-tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac =validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
View(Validation)
val.row <-sort(Validation$Record)
View(temp)
Validation<-temp[val.row,]
View(Validation)
Validation<-data[val.row,]
View(Validation)
View(temp)
Validation<-temp[val.row,]
View(Validation)
Validation<-data[val.row,]
View(Validation)
Test<-data[-c(tra.row,val.row)]
Training
Validation
Test
Test<-data[-c(tra.row,val.row),]
Test
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
Training
Validation
Test
data <- read.csv("POS50.csv")
View(data)
str(data)
data <- read.csv("POS50.csv")
getwd()
##
ㅇ
rm(list = is())
# 데이터 일정하게
# 제품컬럼 모두 만들기 read.transaction
#거래건수 50 아이템 20개 개별아이템의 출현ㄴ횟수 245
#아이템매트릭스 밀도 245/20*50
rm(list = is())
install.packages('arules')
# 데이터 일정하게
# 제품컬럼 모두 만들기 read.transaction
#거래건수 50 아이템 20개 개별아이템의 출현ㄴ횟수 245
#아이템매트릭스 밀도 245/20*50
rm(list = ls())
library(arules)
A.data <- read.transactions("POS50.csv",sep = ',',format = 'basket',skip = 1,cols = 1)
View(A.data)
A.data
head(A.data)
summary(A.data)
inspect(A.data)
inspect(A.data[1:5])
itemFrequencyPlot(A.data)
itemFrequencyPlot(A.data,support=0.3)
itemFrequencyPlot(A.data,topN=10)
apriori(A.data)
apriori(A.data,parameter = list(support=0.2))
apriori(A.data,parameter = list(support=0.2),confidence=0.9)
apriori(A.data,parameter = list(support=0.2,confidence=0.9))
apriori(A.data,parameter = list(support=0.1,confidence=0.9))
apriori(A.data,parameter = list(support=0.2,confidence=0.5))
apriori(A.data,parameter = list(support=0.2,confidence=0.6))
apriori(A.data,parameter = list(support=0.2,confidence=0.4))
apriori(A.data,parameter = list(support=0.2,confidence=0.5))
apriori(A.data,parameter = list(support=0.2,confidence=0.5))
rules20 <-apriori(A.data,parameter = list(support=0.2,confidence=0.5))
inspect(rules20)
inspect(sort(rules20,by='lift'))
inspect(sort(rules20,by='lift')[1:5])
inspect(sort(rules20,decreasing = F,by='lift')[1:5])
sodaR <- subset(rules20,items %in%'soda')
inspect(sodaR)
inspect(sort(sodaR,by='lift')[1:5])
chickenR <- subset(rules20,items %in% 'chicken')
inspect(sort(chickenR,by='lift')[1:5])
length(sodaR)
length(chickenR)
sodaRc9 <- subset(rules20,items %in% 'soda' & confidence>=0.9)
inspect(sodaRc9)
#소다 또는 크래커 추출하라
scR <- subset(rules20,items %in% c('soda','cracker'))
inspect(scR)
#둘다나오게한다
sANDcR <- subset(rules20,items %ain% c('soda','cracker'))
inspect(sANDcR)
#then절에 beer가포함된룰
thenbeerR <-subset(rules20,item %in%'beer')
inspect(thenbeerR)
#then절에 beer가포함된룰
thenbeerR <-subset(rules20,rhs %in%'beer')
inspect(thenbeerR)
#if절에 위스키또는 비어
ifliquorrR <-subset(rules20,lhs %in%c('beer','whiskey'))
inspect(ifliquorrR)
#'er'이라는 음절이포함된 (부분음절)partly in
erR <- subset(rules20,items %pin%'er')
inspect(erR)
library(doBy)
data<-read.csv("pjhData.csv",header = T)
trainingRate <- 0.5
validationRate <- 0.3
pSeed <- 1234
set.seed(pSeed)
Training<-sampleBy(formula = ~Z,frac = trainingRate,replace = F,systematic = F,data=data)
tra.row <-sort(Training$Record)
Training<-data[tra.row,]
temp <-data[-tra.row,]
Validation<-sampleBy(formula = ~Z,frac = validationRate/(1-trainingRate),replace = F,systematic = F,data=temp)
val.row <-sort(Validation$Record)
Validation<-data[val.row,]
Test<-data[-c(tra.row,val.row),]
Training
Validation
Test
rm(list = ls())
